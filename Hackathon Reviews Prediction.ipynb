{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hackathon Reviews Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data (Input Data) - Feedback of hackathon collected from students using Google Forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [\"This was an impactful hackathon, Definitely a good one for beginners\",\n",
    "     \"Great competition! I liked it a lot, The questions were good enough\",\n",
    "     \"Simply outstanding, A great learning platform for students\",\n",
    "     \"loved it! truly great, Its my pleasure to be a part of such innovative hackathon\",\n",
    "     \"bad not upto the mark, tutorials were not good enough\",\n",
    "     \"Could have been better, the ideas were outdated\",\n",
    "     \"Surely a Disappointing Hackathon\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data (Output Data) - Reviews of hackathon: Positive/Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [1,1,1,1,0,0,0] # 1 - Positive, 0 - Negative Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data (Input Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = [\"Good Hackathon, Learned new techniques\",\n",
    "          \"Very Disappointed with the hackathon, bad not up to the mark\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the output of test data (Input Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Cleaning (Preprocessing)\n",
    "- It includes: Tokenization, stopword removal and stemming/lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import clean_text is used for preprocessing of text. It is a user defined python file.\n",
    "import clean_text as ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_clean = [ct.getCleanReview(i) for i in x] #List Comprehension: used to preprocess training input data\n",
    "xt_clean = [ct.getCleanReview(i) for i in x_test] #List Comprehension: used to preprocess testing input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['impact hackathon definit good one beginn', 'great competit like lot question good enough', 'simpli outstand great learn platform student', 'love truli great pleasur part innov hackathon', 'bad upto mark tutori good enough', 'could better idea outdat', 'sure disappoint hackathon']\n"
     ]
    }
   ],
   "source": [
    "print(x_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['good hackathon learn new techniqu', 'disappoint hackathon bad mark']\n"
     ]
    }
   ],
   "source": [
    "print(xt_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vectorization on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      "  0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1\n",
      "  1 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0]\n",
      " [1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1]\n",
      " [0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0]]\n",
      "(7, 63)\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(ngram_range=(1,2))\n",
    "x_vec = cv.fit_transform(x_clean).toarray()\n",
    "print(x_vec)\n",
    "print(x_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'impact': 25,\n",
       " 'hackathon': 21,\n",
       " 'definit': 9,\n",
       " 'good': 14,\n",
       " 'one': 39,\n",
       " 'beginn': 2,\n",
       " 'impact hackathon': 26,\n",
       " 'hackathon definit': 22,\n",
       " 'definit good': 10,\n",
       " 'good one': 16,\n",
       " 'one beginn': 40,\n",
       " 'great': 17,\n",
       " 'competit': 5,\n",
       " 'like': 31,\n",
       " 'lot': 33,\n",
       " 'question': 50,\n",
       " 'enough': 13,\n",
       " 'great competit': 18,\n",
       " 'competit like': 6,\n",
       " 'like lot': 32,\n",
       " 'lot question': 34,\n",
       " 'question good': 51,\n",
       " 'good enough': 15,\n",
       " 'simpli': 52,\n",
       " 'outstand': 42,\n",
       " 'learn': 29,\n",
       " 'platform': 46,\n",
       " 'student': 54,\n",
       " 'simpli outstand': 53,\n",
       " 'outstand great': 43,\n",
       " 'great learn': 19,\n",
       " 'learn platform': 30,\n",
       " 'platform student': 47,\n",
       " 'love': 35,\n",
       " 'truli': 57,\n",
       " 'pleasur': 48,\n",
       " 'part': 44,\n",
       " 'innov': 27,\n",
       " 'love truli': 36,\n",
       " 'truli great': 58,\n",
       " 'great pleasur': 20,\n",
       " 'pleasur part': 49,\n",
       " 'part innov': 45,\n",
       " 'innov hackathon': 28,\n",
       " 'bad': 0,\n",
       " 'upto': 61,\n",
       " 'mark': 37,\n",
       " 'tutori': 59,\n",
       " 'bad upto': 1,\n",
       " 'upto mark': 62,\n",
       " 'mark tutori': 38,\n",
       " 'tutori good': 60,\n",
       " 'could': 7,\n",
       " 'better': 3,\n",
       " 'idea': 23,\n",
       " 'outdat': 41,\n",
       " 'could better': 8,\n",
       " 'better idea': 4,\n",
       " 'idea outdat': 24,\n",
       " 'sure': 55,\n",
       " 'disappoint': 11,\n",
       " 'sure disappoint': 56,\n",
       " 'disappoint hackathon': 12}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bad', 'bad upto', 'beginn', 'better', 'better idea', 'competit', 'competit like', 'could', 'could better', 'definit', 'definit good', 'disappoint', 'disappoint hackathon', 'enough', 'good', 'good enough', 'good one', 'great', 'great competit', 'great learn', 'great pleasur', 'hackathon', 'hackathon definit', 'idea', 'idea outdat', 'impact', 'impact hackathon', 'innov', 'innov hackathon', 'learn', 'learn platform', 'like', 'like lot', 'lot', 'lot question', 'love', 'love truli', 'mark', 'mark tutori', 'one', 'one beginn', 'outdat', 'outstand', 'outstand great', 'part', 'part innov', 'platform', 'platform student', 'pleasur', 'pleasur part', 'question', 'question good', 'simpli', 'simpli outstand', 'student', 'sure', 'sure disappoint', 'truli', 'truli great', 'tutori', 'tutori good', 'upto', 'upto mark']\n"
     ]
    }
   ],
   "source": [
    "print(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vectorization on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "(2, 63)\n"
     ]
    }
   ],
   "source": [
    "xt_vec = cv.transform(xt_clean).toarray()\n",
    "print(xt_vec)\n",
    "cv.get_feature_names()\n",
    "print(xt_vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Applying Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB, GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "print(mnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training \n",
    "mnb.fit(x_vec,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predictions\n",
    "mnb.predict(xt_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.26381939, 0.73618061],\n",
       "       [0.96627979, 0.03372021]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.predict_proba(xt_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.score(x_vec,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) Multivariate Bernoulli Event Model Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb = BernoulliNB(binarize=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n"
     ]
    }
   ],
   "source": [
    "print(bnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.fit(x_vec,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.52662349, 0.47337651],\n",
       "       [0.99757887, 0.00242113]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.predict_proba(xt_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.predict(xt_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.score(x_vec,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
